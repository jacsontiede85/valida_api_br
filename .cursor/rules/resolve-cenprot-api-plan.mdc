---
description: API REST para exposi√ß√£o das funcionalidades de consulta do Resolve CenProt via HTTP endpoints
alwaysApply: false
---
# Plano de A√ß√£o - API Interface Resolve CenProt

## Vis√£o Geral da API

**Objetivo**: Criar uma API REST para exposi√ß√£o das funcionalidades de consulta do Resolve CenProt via HTTP endpoints.

**Tecnologias**:
- **FastAPI**: Framework web Python ass√≠ncrono
- **Pydantic**: Valida√ß√£o e serializa√ß√£o de dados (j√° usado no projeto)
- **Playwright**: Reutilizar sess√£o de navegador existente
- **Uvicorn**: Servidor ASGI para produ√ß√£o

## Estrutura da API

### Endpoints Principais

1. **GET /status** - Verifica√ß√£o de sa√∫de do servi√ßo
2. **POST /cnpj** - Consulta de CNPJ espec√≠fico
3. **GET /session/status** - Status da sess√£o do navegador
4. **POST /session/renew** - Renovar sess√£o (re-login)

## Arquitetura do Projeto API

```
resolve_cenprot/
‚îú‚îÄ‚îÄ api/                           # Nova pasta da API
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                   # Ponto de entrada FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status.py            # Rota /status
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cnpj.py              # Rota /cnpj
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ session.py           # Rotas de sess√£o
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_models.py        # Models de request/response da API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error_models.py      # Models de erro
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session_manager.py   # Gerenciamento de sess√£o persistente
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraping_service.py  # Service layer para scraping
‚îÇ   ‚îî‚îÄ‚îÄ middleware/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ cors.py              # Configura√ß√£o CORS
‚îÇ       ‚îî‚îÄ‚îÄ error_handler.py     # Handler de erros global
‚îú‚îÄ‚îÄ src/                          # C√≥digo existente (reutilizar)
‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îú‚îÄ‚îÄ scraping/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ requirements-api.txt          # Depend√™ncias adicionais da API
```

## Fase 1: Setup Inicial da API

### 1.1 Depend√™ncias Adicionais

```python
# requirements-api.txt (adicionar ao requirements.txt existente)
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic-settings>=2.0.0
python-multipart>=0.0.6
```

### 1.2 Configura√ß√£o Base da API

```python
# api/main.py
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import uvicorn
import sys
from pathlib import Path

# Adicionar src ao path para reutilizar c√≥digo existente
sys.path.append(str(Path(__file__).parent.parent / "src"))

from api.services.session_manager import SessionManager
from api.routers import status, cnpj, session
from api.middleware.error_handler import add_error_handlers

# Gerenciador de sess√£o global
session_manager = SessionManager()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gerencia ciclo de vida da aplica√ß√£o"""
    # Startup: Inicializar sess√£o do navegador
    await session_manager.initialize()
    
    yield
    
    # Shutdown: Limpar recursos
    await session_manager.cleanup()

# Criar aplica√ß√£o FastAPI
app = FastAPI(
    title="Resolve CenProt API",
    description="API para consulta de protestos via resolve.cenprot.org.br",
    version="1.0.0",
    lifespan=lifespan
)

# Middleware CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configurar conforme necess√°rio
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Adicionar handlers de erro
add_error_handlers(app)

# Incluir routers
app.include_router(status.router, tags=["Status"])
app.include_router(cnpj.router, tags=["Consulta"])
app.include_router(session.router, prefix="/session", tags=["Sess√£o"])

if __name__ == "__main__":
    uvicorn.run(
        "api.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # Apenas para desenvolvimento
        log_level="info"
    )
```

## Fase 2: Models da API

### 2.1 Models de Request/Response

```python
# api/models/api_models.py
from pydantic import BaseModel, Field, validator
from typing import Optional, Dict, Any
from datetime import datetime
import re

class CNPJRequest(BaseModel):
    """Request para consulta de CNPJ"""
    cnpj: str = Field(..., description="CNPJ no formato XX.XXX.XXX/XXXX-XX ou apenas n√∫meros")
    
    @validator('cnpj')
    def validate_cnpj(cls, v):
        # Remove formata√ß√£o
        cnpj_numbers = re.sub(r'[^0-9]', '', v)
        
        if len(cnpj_numbers) != 14:
            raise ValueError('CNPJ deve conter 14 d√≠gitos')
            
        # Formatar CNPJ
        return f"{cnpj_numbers[:2]}.{cnpj_numbers[2:5]}.{cnpj_numbers[5:8]}/{cnpj_numbers[8:12]}-{cnpj_numbers[12:]}"

class CNPJResponse(BaseModel):
    """Response da consulta de CNPJ"""
    success: bool = Field(description="Se a consulta foi bem-sucedida")
    data: Optional[Dict[str, Any]] = Field(default=None, description="Dados da consulta (formato atual)")
    message: str = Field(description="Mensagem de status")
    timestamp: datetime = Field(default_factory=datetime.now, description="Timestamp da consulta")
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }

class StatusResponse(BaseModel):
    """Response do status do servi√ßo"""
    service: str = Field(default="Resolve CenProt API")
    status: str = Field(description="Status do servi√ßo")
    version: str = Field(default="1.0.0")
    session_active: bool = Field(description="Se a sess√£o do navegador est√° ativa")
    last_login: Optional[datetime] = Field(default=None, description="√öltimo login realizado")
    timestamp: datetime = Field(default_factory=datetime.now)

class SessionStatusResponse(BaseModel):
    """Response do status da sess√£o"""
    active: bool = Field(description="Se a sess√£o est√° ativa")
    logged_in: bool = Field(description="Se est√° logado no resolve.cenprot.org.br")
    last_activity: Optional[datetime] = Field(default=None, description="√öltima atividade")
    login_cnpj: Optional[str] = Field(default=None, description="CNPJ usado no login")
```

### 2.2 Models de Erro

```python
# api/models/error_models.py
from pydantic import BaseModel
from typing import Optional, Dict, Any

class APIError(BaseModel):
    """Modelo padr√£o de erro da API"""
    error: str = Field(description="Tipo do erro")
    message: str = Field(description="Mensagem do erro")
    detail: Optional[Dict[str, Any]] = Field(default=None, description="Detalhes adicionais")
    timestamp: datetime = Field(default_factory=datetime.now)

class ValidationError(APIError):
    """Erro de valida√ß√£o"""
    error: str = "validation_error"

class SessionError(APIError):
    """Erro relacionado √† sess√£o"""
    error: str = "session_error"

class ScrapingError(APIError):
    """Erro durante scraping"""
    error: str = "scraping_error"
```

## Fase 3: Gerenciamento de Sess√£o Persistente

### 3.1 Session Manager

```python
# api/services/session_manager.py
from typing import Optional
from datetime import datetime, timedelta
import asyncio
import sys
from pathlib import Path

# Importar c√≥digo existente
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

from browser.browser_manager import BrowserManager
from auth.login_manager import LoginManager
from auth.email_extractor import EmailCodeExtractor
from config.settings import Settings

class SessionManager:
    """Gerencia sess√£o persistente do navegador"""
    
    def __init__(self):
        self.browser_manager: Optional[BrowserManager] = None
        self.login_manager: Optional[LoginManager] = None
        self.email_extractor: Optional[EmailCodeExtractor] = None
        self.page = None
        self.context = None
        
        self.is_initialized = False
        self.is_logged_in = False
        self.last_login: Optional[datetime] = None
        self.last_activity: Optional[datetime] = None
        self.login_cnpj: Optional[str] = None
        
        self.settings = Settings()
        
    async def initialize(self):
        """Inicializa navegador e componentes"""
        if self.is_initialized:
            return
            
        try:
            # Inicializar componentes
            self.browser_manager = BrowserManager()
            self.email_extractor = EmailCodeExtractor(
                self.settings.RESOLVE_EMAIL,
                self.settings.RESOLVE_EMAIL_PASSWORD
            )
            self.login_manager = LoginManager(self.email_extractor)
            
            # Inicializar navegador
            self.context = await self.browser_manager.initialize()
            self.page = await self.browser_manager.new_page()
            
            self.is_initialized = True
            
            # Tentar login inicial
            await self._perform_initial_login()
            
        except Exception as e:
            logger.error("erro_inicializar_session_manager", error=str(e))
            raise
    
    async def _perform_initial_login(self):
        """Realiza login inicial autom√°tico"""
        try:
            cnpj_login = self.settings.RESOLVE_CENPROT_LOGIN
            success = await self.login_manager.perform_full_login(self.page, cnpj_login)
            
            if success:
                self.is_logged_in = True
                self.last_login = datetime.now()
                self.login_cnpj = cnpj_login
                logger.info("login_inicial_realizado_com_sucesso", cnpj=cnpj_login)
            else:
                logger.warning("falha_no_login_inicial", cnpj=cnpj_login)
                
        except Exception as e:
            logger.error("erro_login_inicial", error=str(e))
    
    async def ensure_logged_in(self) -> bool:
        """Garante que est√° logado, faz re-login se necess√°rio"""
        if not self.is_initialized:
            await self.initialize()
        
        # Verificar se sess√£o ainda √© v√°lida
        if self.is_logged_in and self._is_session_valid():
            self.last_activity = datetime.now()
            return True
            
        # Tentar re-login
        try:
            await self._perform_initial_login()
            return self.is_logged_in
        except Exception as e:
            logger.error("erro_ensure_logged_in", error=str(e))
            return False
    
    def _is_session_valid(self) -> bool:
        """Verifica se a sess√£o ainda √© v√°lida (√∫ltimas 2 horas)"""
        if not self.last_login:
            return False
            
        session_age = datetime.now() - self.last_login
        return session_age < timedelta(hours=2)
    
    async def get_scraping_components(self):
        """Retorna componentes para scraping"""
        if not await self.ensure_logged_in():
            raise Exception("N√£o foi poss√≠vel estabelecer sess√£o logada")
            
        return {
            "page": self.page,
            "context": self.context,
            "browser_manager": self.browser_manager
        }
    
    async def renew_session(self) -> bool:
        """Force renewal da sess√£o"""
        try:
            self.is_logged_in = False
            return await self.ensure_logged_in()
        except Exception as e:
            logger.error("erro_renew_session", error=str(e))
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """Retorna status atual da sess√£o"""
        return {
            "active": self.is_initialized,
            "logged_in": self.is_logged_in,
            "last_activity": self.last_activity,
            "last_login": self.last_login,
            "login_cnpj": self.login_cnpj
        }
    
    async def cleanup(self):
        """Limpa recursos"""
        try:
            if self.email_extractor:
                self.email_extractor.disconnect()
            if self.browser_manager:
                await self.browser_manager.close()
        except Exception as e:
            logger.error("erro_cleanup_session_manager", error=str(e))
```

## Fase 3.5: Gerenciamento de M√∫ltiplas Requisi√ß√µes

### 3.5.1 Problema de Concorr√™ncia

**Situa√ß√£o Atual:**
- Uma √∫nica sess√£o de navegador compartilhada globalmente
- Uma √∫nica p√°gina para todas as requisi√ß√µes simult√¢neas
- Risk de race conditions entre consultas paralelas

**Solu√ß√µes Dispon√≠veis:**
1. **Lock/Sem√°foro**: Serializa requisi√ß√µes (uma por vez)
2. **Pool de P√°ginas**: M√∫ltiplas p√°ginas paralelas (RECOMENDADO)
3. **Queue + Workers**: Fila de processamento ass√≠ncrono

### 3.5.2 Solu√ß√£o Recomendada: Pool de P√°ginas

```python
# api/services/session_manager.py (vers√£o com pool de p√°ginas)
import asyncio
from typing import Optional, Dict, Any
from datetime import datetime, timedelta

class SessionManager:
    """Gerencia sess√£o persistente com pool de p√°ginas para m√∫ltiplas requisi√ß√µes"""
    
    def __init__(self, pool_size: int = 3):
        self.browser_manager: Optional[BrowserManager] = None
        self.login_manager: Optional[LoginManager] = None
        self.email_extractor: Optional[EmailCodeExtractor] = None
        self.context = None
        
        # Pool de p√°ginas para requisi√ß√µes paralelas
        self.pool_size = pool_size
        self.page_pool = asyncio.Queue(maxsize=pool_size)
        self.active_pages = {}  # Rastreamento de p√°ginas em uso
        
        self.is_initialized = False
        self.is_logged_in = False
        self.last_login: Optional[datetime] = None
        self.last_activity: Optional[datetime] = None
        self.login_cnpj: Optional[str] = None
        
        self.settings = Settings()
        
    async def initialize(self):
        """Inicializa navegador e cria pool de p√°ginas"""
        if self.is_initialized:
            return
            
        try:
            # Inicializar componentes base
            self.browser_manager = BrowserManager()
            self.email_extractor = EmailCodeExtractor(
                self.settings.RESOLVE_EMAIL,
                self.settings.RESOLVE_EMAIL_PASSWORD
            )
            self.login_manager = LoginManager(self.email_extractor)
            
            # Inicializar contexto compartilhado (sess√£o/cookies)
            self.context = await self.browser_manager.initialize()
            
            # Realizar login inicial em p√°gina tempor√°ria
            await self._perform_initial_login()
            
            if self.is_logged_in:
                # Criar pool de p√°ginas autenticadas
                await self._create_page_pool()
                self.is_initialized = True
                logger.info("session_manager_inicializado_com_pool", pool_size=self.pool_size)
            else:
                raise Exception("Falha no login inicial")
                
        except Exception as e:
            logger.error("erro_inicializar_session_manager_pool", error=str(e))
            raise
    
    async def _perform_initial_login(self):
        """Realiza login inicial para estabelecer sess√£o no contexto"""
        try:
            # P√°gina tempor√°ria apenas para login
            temp_page = await self.context.new_page()
            
            cnpj_login = self.settings.RESOLVE_CENPROT_LOGIN
            success = await self.login_manager.perform_full_login(temp_page, cnpj_login)
            
            if success:
                self.is_logged_in = True
                self.last_login = datetime.now()
                self.login_cnpj = cnpj_login
                logger.info("login_inicial_realizado_pool", cnpj=cnpj_login)
            else:
                logger.warning("falha_login_inicial_pool", cnpj=cnpj_login)
            
            # Fechar p√°gina tempor√°ria
            await temp_page.close()
                
        except Exception as e:
            logger.error("erro_login_inicial_pool", error=str(e))
            if 'temp_page' in locals():
                await temp_page.close()
    
    async def _create_page_pool(self):
        """Cria pool de p√°ginas reutiliz√°veis com sess√£o autenticada"""
        for i in range(self.pool_size):
            try:
                # Criar nova p√°gina no contexto autenticado
                page = await self.context.new_page()
                
                page_info = {
                    "page": page,
                    "id": f"page_{i}",
                    "created_at": datetime.now(),
                    "usage_count": 0,
                    "in_use": False
                }
                
                # Adicionar ao pool
                await self.page_pool.put(page_info)
                
                logger.info("pagina_criada_no_pool", 
                          page_id=page_info["id"], 
                          pool_size=i+1)
                          
            except Exception as e:
                logger.error("erro_criar_pagina_pool", page_index=i, error=str(e))
    
    async def get_page_from_pool(self, timeout: int = 30):
        """Obt√©m p√°gina do pool para uso exclusivo"""
        try:
            # Aguardar p√°gina dispon√≠vel com timeout
            page_info = await asyncio.wait_for(
                self.page_pool.get(), 
                timeout=timeout
            )
            
            # Marcar como em uso
            page_info["in_use"] = True
            page_info["usage_count"] += 1
            page_info["last_used"] = datetime.now()
            
            # Registrar p√°gina ativa
            self.active_pages[page_info["id"]] = page_info
            
            self.last_activity = datetime.now()
            
            logger.info("pagina_obtida_do_pool", 
                       page_id=page_info["id"],
                       usage_count=page_info["usage_count"],
                       pool_remaining=self.page_pool.qsize())
            
            return page_info
            
        except asyncio.TimeoutError:
            logger.error("timeout_obter_pagina_pool", 
                        timeout=timeout,
                        active_pages=len(self.active_pages),
                        pool_size=self.pool_size)
            raise Exception(f"Timeout: todas as {self.pool_size} p√°ginas do pool est√£o em uso")
        except Exception as e:
            logger.error("erro_obter_pagina_pool", error=str(e))
            raise
    
    async def return_page_to_pool(self, page_info: dict):
        """Retorna p√°gina para o pool ap√≥s uso"""
        try:
            page_id = page_info["id"]
            
            # Remover do registro de p√°ginas ativas
            if page_id in self.active_pages:
                del self.active_pages[page_id]
            
            # Marcar como dispon√≠vel
            page_info["in_use"] = False
            page_info["returned_at"] = datetime.now()
            
            # Limpar estado da p√°gina (navegar para blank)
            try:
                await page_info["page"].goto("about:blank")
            except:
                # Se falhar ao limpar, p√°gina pode estar em estado inconsistente
                logger.warning("falha_limpar_pagina", page_id=page_id)
            
            # Retornar ao pool
            await self.page_pool.put(page_info)
            
            logger.info("pagina_retornada_ao_pool", 
                       page_id=page_id,
                       usage_count=page_info["usage_count"],
                       pool_available=self.page_pool.qsize())
            
        except Exception as e:
            logger.error("erro_retornar_pagina_pool", 
                        page_id=page_info.get("id", "unknown"), 
                        error=str(e))
    
    async def get_pool_status(self) -> Dict[str, Any]:
        """Retorna status do pool de p√°ginas"""
        return {
            "pool_size": self.pool_size,
            "available_pages": self.page_pool.qsize(),
            "active_pages": len(self.active_pages),
            "active_page_ids": list(self.active_pages.keys()),
            "total_pages_created": self.pool_size
        }
    
    def _is_session_valid(self) -> bool:
        """Verifica se a sess√£o ainda √© v√°lida (√∫ltimas 2 horas)"""
        if not self.last_login:
            return False
            
        session_age = datetime.now() - self.last_login
        return session_age < timedelta(hours=2)
    
    async def ensure_logged_in(self) -> bool:
        """Garante que a sess√£o est√° ativa"""
        if not self.is_initialized:
            await self.initialize()
        
        if self.is_logged_in and self._is_session_valid():
            return True
            
        # Re-login necess√°rio
        try:
            await self._perform_initial_login()
            return self.is_logged_in
        except Exception as e:
            logger.error("erro_ensure_logged_in_pool", error=str(e))
            return False
    
    async def renew_session(self) -> bool:
        """Force renewal da sess√£o"""
        try:
            self.is_logged_in = False
            return await self.ensure_logged_in()
        except Exception as e:
            logger.error("erro_renew_session_pool", error=str(e))
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """Retorna status completo da sess√£o com informa√ß√µes do pool"""
        base_status = {
            "active": self.is_initialized,
            "logged_in": self.is_logged_in,
            "last_activity": self.last_activity,
            "last_login": self.last_login,
            "login_cnpj": self.login_cnpj
        }
        
        # Adicionar informa√ß√µes do pool se dispon√≠vel
        if hasattr(self, 'page_pool'):
            pool_status = asyncio.create_task(self.get_pool_status())
            base_status.update({
                "pool_enabled": True,
                "pool_size": self.pool_size,
                "available_pages": self.page_pool.qsize(),
                "active_requests": len(self.active_pages)
            })
        else:
            base_status["pool_enabled"] = False
        
        return base_status
    
    async def cleanup(self):
        """Limpa todos os recursos incluindo pool de p√°ginas"""
        try:
            # Fechar todas as p√°ginas ativas
            for page_info in self.active_pages.values():
                try:
                    await page_info["page"].close()
                except:
                    pass
            
            # Fechar p√°ginas no pool
            while not self.page_pool.empty():
                try:
                    page_info = await self.page_pool.get()
                    await page_info["page"].close()
                except:
                    pass
            
            # Cleanup padr√£o
            if self.email_extractor:
                self.email_extractor.disconnect()
            if self.browser_manager:
                await self.browser_manager.close()
                
            logger.info("session_manager_pool_cleanup_completo")
            
        except Exception as e:
            logger.error("erro_cleanup_session_manager_pool", error=str(e))
```

### 3.5.3 Scraping Service Atualizado para Pool

```python
# api/services/scraping_service.py (vers√£o com pool)
from typing import Dict, Any
import sys
from pathlib import Path

# Importar c√≥digo existente
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

from scraping.protest_scraper import ProtestScraper
from models.protest_models import ConsultaCNPJResult
from .session_manager import SessionManager

class ScrapingService:
    """Service layer para opera√ß√µes de scraping com suporte a m√∫ltiplas requisi√ß√µes"""
    
    def __init__(self, session_manager: SessionManager):
        self.session_manager = session_manager
    
    async def consultar_cnpj(self, cnpj: str) -> ConsultaCNPJResult:
        """
        Realiza consulta de um CNPJ usando p√°gina do pool
        """
        page_info = None
        try:
            # Verificar se sess√£o est√° ativa
            if not await self.session_manager.ensure_logged_in():
                raise Exception("N√£o foi poss√≠vel estabelecer sess√£o logada")
            
            # Obter p√°gina exclusiva do pool
            page_info = await self.session_manager.get_page_from_pool()
            page = page_info["page"]
            
            logger.info("iniciando_consulta_com_pagina_pool", 
                       cnpj=cnpj, 
                       page_id=page_info["id"])
            
            # Criar scraper com p√°gina dedicada
            scraper = ProtestScraper(page)
            scraper.current_cnpj = cnpj
            
            # Realizar consulta (reutiliza c√≥digo existente)
            result = await scraper.consultar_cnpj(cnpj)
            
            logger.info("consulta_finalizada_sucesso_pool", 
                       cnpj=cnpj, 
                       page_id=page_info["id"],
                       tem_protestos=bool(result.cenprotProtestos))
            
            return result
            
        except Exception as e:
            logger.error("erro_scraping_service_consultar_pool", 
                        cnpj=cnpj, 
                        page_id=page_info["id"] if page_info else "none",
                        error=str(e))
            raise
        finally:
            # SEMPRE retornar p√°gina ao pool
            if page_info:
                await self.session_manager.return_page_to_pool(page_info)
    
    async def get_session_health(self) -> Dict[str, Any]:
        """Verifica sa√∫de da sess√£o incluindo status do pool"""
        try:
            status = self.session_manager.get_status()
            pool_status = await self.session_manager.get_pool_status()
            
            health = {
                **status,
                **pool_status,
                "can_scrape": status["active"] and status["logged_in"],
                "needs_renewal": not self.session_manager._is_session_valid(),
                "concurrent_capacity": self.session_manager.pool_size,
                "current_load": len(self.session_manager.active_pages)
            }
            
            return health
            
        except Exception as e:
            logger.error("erro_get_session_health_pool", error=str(e))
            return {"error": str(e)}
```

### 3.5.4 Configura√ß√£o FastAPI para Pool

```python
# api/main.py (vers√£o com pool de p√°ginas)
from contextlib import asynccontextmanager

# Configurar SessionManager com pool
session_manager = SessionManager(pool_size=3)  # 3 requisi√ß√µes simult√¢neas

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gerencia ciclo de vida com pool de p√°ginas"""
    try:
        # Startup: Inicializar pool
        await session_manager.initialize()
        logger.info("api_iniciada_com_pool_de_paginas", pool_size=session_manager.pool_size)
        
        yield
        
    finally:
        # Shutdown: Limpar pool
        await session_manager.cleanup()
        logger.info("api_encerrada_pool_limpo")

# Middleware para monitoramento de carga
@app.middleware("http")
async def monitor_concurrent_requests(request: Request, call_next):
    if request.url.path.startswith("/cnpj"):
        pool_status = await session_manager.get_pool_status()
        
        # Log da carga atual
        logger.info("requisicao_recebida", 
                   path=request.url.path,
                   available_pages=pool_status["available_pages"],
                   active_pages=pool_status["active_pages"])
        
        # Adicionar headers de status
        response = await call_next(request)
        response.headers["X-Pool-Available"] = str(pool_status["available_pages"])
        response.headers["X-Pool-Active"] = str(pool_status["active_pages"])
        
        return response
    else:
        return await call_next(request)
```

### 3.5.5 Vantagens da Solu√ß√£o Pool de P√°ginas

**‚úÖ Benef√≠cios:**
- **Consultas Paralelas**: 3-5 requisi√ß√µes simult√¢neas
- **Sess√£o Compartilhada**: Login √∫nico com cookies do contexto
- **Isolamento**: Cada requisi√ß√£o usa p√°gina exclusiva
- **Performance**: Sem overhead de cria√ß√£o/destrui√ß√£o de p√°ginas
- **Reutiliza√ß√£o**: P√°ginas retornam ao pool ap√≥s uso

**‚ö†Ô∏è Considera√ß√µes:**
- **Mem√≥ria**: ~50-100MB por p√°gina adicional
- **Complexidade**: Gerenciamento do ciclo de vida das p√°ginas
- **Limite**: Pool size definido na inicializa√ß√£o

**üìä Capacidade Esperada:**
- **3 requisi√ß√µes simult√¢neas** com pool_size=3
- **Tempo m√©dio por consulta**: 15-30 segundos
- **Throughput**: ~6-12 consultas por minuto

## Fase 4: Service Layer

### 4.1 Scraping Service

```python
# api/services/scraping_service.py
from typing import Dict, Any
import sys
from pathlib import Path

# Importar c√≥digo existente
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

from scraping.protest_scraper import ProtestScraper
from models.protest_models import ConsultaCNPJResult
from .session_manager import SessionManager

class ScrapingService:
    """Service layer para opera√ß√µes de scraping"""
    
    def __init__(self, session_manager: SessionManager):
        self.session_manager = session_manager
    
    async def consultar_cnpj(self, cnpj: str) -> ConsultaCNPJResult:
        """
        Realiza consulta de um CNPJ reutilizando a sess√£o ativa
        """
        try:
            # Obter componentes da sess√£o ativa
            components = await self.session_manager.get_scraping_components()
            page = components["page"]
            
            # Criar scraper com p√°gina logada
            scraper = ProtestScraper(page)
            scraper.current_cnpj = cnpj  # Set current CNPJ for context
            
            # Realizar consulta (reutiliza c√≥digo existente)
            result = await scraper.consultar_cnpj(cnpj)
            
            return result
            
        except Exception as e:
            logger.error("erro_scraping_service_consultar", cnpj=cnpj, error=str(e))
            raise
    
    async def get_session_health(self) -> Dict[str, Any]:
        """Verifica sa√∫de da sess√£o de scraping"""
        try:
            status = self.session_manager.get_status()
            
            # Adicionar verifica√ß√µes espec√≠ficas de sa√∫de
            health = {
                **status,
                "can_scrape": status["active"] and status["logged_in"],
                "needs_renewal": not self.session_manager._is_session_valid()
            }
            
            return health
            
        except Exception as e:
            logger.error("erro_get_session_health", error=str(e))
            return {"error": str(e)}
```

## Fase 5: Implementa√ß√£o dos Routers

### 5.1 Router de Status

```python
# api/routers/status.py
from fastapi import APIRouter, Depends
from api.models.api_models import StatusResponse
from api.services.session_manager import SessionManager
from api.main import session_manager  # Import do gerenciador global

router = APIRouter()

@router.get("/status", response_model=StatusResponse)
async def get_status():
    """
    Verifica status do servi√ßo e da sess√£o
    """
    try:
        session_status = session_manager.get_status()
        
        return StatusResponse(
            status="online",
            session_active=session_status["active"],
            last_login=session_status["last_login"]
        )
        
    except Exception as e:
        return StatusResponse(
            status="error",
            session_active=False,
            last_login=None
        )

@router.get("/health")
async def health_check():
    """Health check simples para load balancers"""
    return {"status": "healthy"}
```

### 5.2 Router de CNPJ

```python
# api/routers/cnpj.py
from fastapi import APIRouter, HTTPException, Depends
from api.models.api_models import CNPJRequest, CNPJResponse
from api.models.error_models import ValidationError, SessionError, ScrapingError
from api.services.scraping_service import ScrapingService
from api.main import session_manager

router = APIRouter()

def get_scraping_service() -> ScrapingService:
    """Dependency injection para ScrapingService"""
    return ScrapingService(session_manager)

@router.post("/cnpj", response_model=CNPJResponse)
async def consultar_cnpj(
    request: CNPJRequest,
    scraping_service: ScrapingService = Depends(get_scraping_service)
):
    """
    Realiza consulta de CNPJ e retorna dados no formato padr√£o
    """
    try:
        # Validar e normalizar CNPJ j√° √© feito pelo modelo Pydantic
        cnpj = request.cnpj
        
        # Realizar consulta
        result = await scraping_service.consultar_cnpj(cnpj)
        
        # Converter para dict usando model_dump (Pydantic V2)
        result_dict = result.model_dump()
        
        return CNPJResponse(
            success=True,
            data=result_dict,
            message=f"Consulta realizada com sucesso para CNPJ {cnpj}"
        )
        
    except ValueError as e:
        # Erro de valida√ß√£o do CNPJ
        raise HTTPException(
            status_code=400,
            detail=ValidationError(message=str(e)).dict()
        )
        
    except Exception as e:
        # Verificar se √© erro de sess√£o
        if "sess√£o" in str(e).lower() or "login" in str(e).lower():
            raise HTTPException(
                status_code=503,
                detail=SessionError(message=f"Erro de sess√£o: {str(e)}").dict()
            )
        
        # Outros erros de scraping
        raise HTTPException(
            status_code=500,
            detail=ScrapingError(message=f"Erro durante consulta: {str(e)}").dict()
        )

@router.get("/cnpj/{cnpj}", response_model=CNPJResponse)
async def consultar_cnpj_get(
    cnpj: str,
    scraping_service: ScrapingService = Depends(get_scraping_service)
):
    """
    Consulta CNPJ via GET (alternativa ao POST)
    """
    # Criar request object e reutilizar l√≥gica do POST
    request = CNPJRequest(cnpj=cnpj)
    return await consultar_cnpj(request, scraping_service)
```

### 5.3 Router de Sess√£o

```python
# api/routers/session.py
from fastapi import APIRouter, HTTPException
from api.models.api_models import SessionStatusResponse
from api.main import session_manager

router = APIRouter()

@router.get("/status", response_model=SessionStatusResponse)
async def get_session_status():
    """
    Retorna status detalhado da sess√£o do navegador
    """
    try:
        status = session_manager.get_status()
        
        return SessionStatusResponse(
            active=status["active"],
            logged_in=status["logged_in"],
            last_activity=status["last_activity"],
            login_cnpj=status["login_cnpj"]
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao obter status da sess√£o: {str(e)}")

@router.post("/renew")
async def renew_session():
    """
    Force renewal da sess√£o (re-login)
    """
    try:
        success = await session_manager.renew_session()
        
        if success:
            return {"message": "Sess√£o renovada com sucesso", "success": True}
        else:
            raise HTTPException(status_code=500, detail="Falha ao renovar sess√£o")
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao renovar sess√£o: {str(e)}")

@router.delete("/logout")
async def logout_session():
    """
    Encerra sess√£o atual (for√ßa novo login na pr√≥xima consulta)
    """
    try:
        session_manager.is_logged_in = False
        session_manager.last_login = None
        
        return {"message": "Sess√£o encerrada", "success": True}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao encerrar sess√£o: {str(e)}")
```

## Fase 6: Middleware e Error Handling

### 6.1 Error Handler Global

```python
# api/middleware/error_handler.py
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

def add_error_handlers(app: FastAPI):
    """Adiciona handlers de erro globais"""
    
    @app.exception_handler(StarletteHTTPException)
    async def http_exception_handler(request: Request, exc: StarletteHTTPException):
        return JSONResponse(
            status_code=exc.status_code,
            content={
                "error": "http_error",
                "message": exc.detail,
                "status_code": exc.status_code,
                "timestamp": datetime.now().isoformat()
            }
        )
    
    @app.exception_handler(RequestValidationError)
    async def validation_exception_handler(request: Request, exc: RequestValidationError):
        return JSONResponse(
            status_code=422,
            content={
                "error": "validation_error",
                "message": "Dados de entrada inv√°lidos",
                "detail": exc.errors(),
                "timestamp": datetime.now().isoformat()
            }
        )
    
    @app.exception_handler(Exception)
    async def general_exception_handler(request: Request, exc: Exception):
        logger.error(f"Erro n√£o tratado: {str(exc)}", exc_info=True)
        
        return JSONResponse(
            status_code=500,
            content={
                "error": "internal_error",
                "message": "Erro interno do servidor",
                "timestamp": datetime.now().isoformat()
            }
        )
```

## Fase 7: Documenta√ß√£o e Deploy

### 7.1 Configura√ß√£o de Deploy

```python
# api/deploy/gunicorn.conf.py
"""Configura√ß√£o do Gunicorn para produ√ß√£o"""

bind = "0.0.0.0:8000"
workers = 1  # Importante: apenas 1 worker devido √† sess√£o do navegador
worker_class = "uvicorn.workers.UvicornWorker"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 100
timeout = 300  # 5 minutos para consultas longas
keepalive = 5
preload_app = True
```

### 7.2 Docker Configuration

```dockerfile
# Dockerfile.api
FROM python:3.11-slim

WORKDIR /app

# Instalar depend√™ncias do Playwright
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt requirements-api.txt ./
RUN pip install --no-cache-dir -r requirements.txt -r requirements-api.txt

# Instalar navegadores do Playwright
RUN playwright install chromium
RUN playwright install-deps

COPY . .

EXPOSE 8000

CMD ["python", "-m", "api.main"]
```

### 7.3 Scripts de Deploy

```bash
# scripts/start_api.py
#!/usr/bin/env python3
"""Script para iniciar a API"""

import subprocess
import sys
from pathlib import Path

def start_api(port: int = 8000, workers: int = 1, reload: bool = False):
    """Inicia a API usando uvicorn"""
    
    # Mudar para diret√≥rio do projeto
    project_root = Path(__file__).parent.parent
    
    cmd = [
        "uvicorn",
        "api.main:app",
        f"--host=0.0.0.0",
        f"--port={port}",
        f"--workers={workers}",
    ]
    
    if reload:
        cmd.append("--reload")
    
    print(f"üöÄ Iniciando Resolve CenProt API na porta {port}...")
    print(f"üìù Documenta√ß√£o dispon√≠vel em: http://localhost:{port}/docs")
    
    try:
        subprocess.run(cmd, cwd=project_root)
    except KeyboardInterrupt:
        print("\nüõë API encerrada pelo usu√°rio")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Iniciar Resolve CenProt API")
    parser.add_argument("--port", type=int, default=8000, help="Porta da API")
    parser.add_argument("--reload", action="store_true", help="Habilitar reload autom√°tico")
    
    args = parser.parse_args()
    start_api(port=args.port, reload=args.reload)
```

## Fase 8: Testes da API

### 8.1 Testes B√°sicos

```python
# tests/test_api.py
import pytest
from fastapi.testclient import TestClient
from api.main import app

client = TestClient(app)

def test_status_endpoint():
    """Testa endpoint de status"""
    response = client.get("/status")
    assert response.status_code == 200
    
    data = response.json()
    assert "service" in data
    assert "status" in data
    assert data["service"] == "Resolve CenProt API"

def test_health_endpoint():
    """Testa endpoint de health"""
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json() == {"status": "healthy"}

@pytest.mark.asyncio
async def test_cnpj_endpoint_valid():
    """Testa consulta de CNPJ v√°lido"""
    cnpj_data = {"cnpj": "12.345.678/0001-90"}
    
    response = client.post("/cnpj", json=cnpj_data)
    
    # Pode falhar se sess√£o n√£o estiver ativa, mas estrutura deve estar correta
    data = response.json()
    assert "success" in data
    assert "message" in data
    assert "timestamp" in data

def test_cnpj_endpoint_invalid():
    """Testa consulta de CNPJ inv√°lido"""
    cnpj_data = {"cnpj": "12345"}  # CNPJ inv√°lido
    
    response = client.post("/cnpj", json=cnpj_data)
    assert response.status_code == 400
    
    data = response.json()
    assert "detail" in data
```

## Cronograma de Implementa√ß√£o

### Semana 1: Estrutura Base da API
- [ ] Setup do FastAPI e estrutura de pastas
- [ ] Models de request/response
- [ ] Configura√ß√£o b√°sica de rotas
- [ ] Middleware de CORS e error handling

### Semana 2: Gerenciamento de Sess√£o
- [ ] Implementar SessionManager b√°sico
- [ ] Integra√ß√£o com c√≥digo existente de login
- [ ] Testes de persist√™ncia de sess√£o
- [ ] Implementar Pool de P√°ginas para m√∫ltiplas requisi√ß√µes
- [ ] Endpoints de gerenciamento de sess√£o

### Semana 3: Service Layer e Rotas Principais
- [ ] ScrapingService integrado ao c√≥digo atual
- [ ] Router /cnpj com valida√ß√£o
- [ ] Router /status com health checks
- [ ] Tratamento de erros espec√≠ficos

### Semana 4: Testes e Deploy
- [ ] Testes automatizados da API
- [ ] Configura√ß√£o de deploy
- [ ] Documenta√ß√£o Swagger/OpenAPI
- [ ] Scripts de inicializa√ß√£o

## Benef√≠cios da Implementa√ß√£o

### Para Desenvolvimento
- **Reutiliza√ß√£o**: Aproveita 100% do c√≥digo existente
- **Sess√£o Persistente**: Navegador fica ativo entre consultas
- **Performance**: N√£o h√° overhead de login a cada consulta
- **Escalabilidade**: Base para m√∫ltiplas inst√¢ncias no futuro

### Para Uso
- **Interface Padronizada**: API REST padr√£o da ind√∫stria
- **Documenta√ß√£o Autom√°tica**: Swagger UI integrado
- **Valida√ß√£o Autom√°tica**: Pydantic cuida da valida√ß√£o
- **Monitoramento**: Endpoints de status para health checks

## Considera√ß√µes de Produ√ß√£o

### Seguran√ßa
- Implementar autentica√ß√£o para API (API Keys, JWT)
- Rate limiting por IP/usu√°rio
- Logging de todas as requisi√ß√µes
- Sanitiza√ß√£o de dados de entrada

### Performance
- **Pool de P√°ginas**: 3-5 requisi√ß√µes simult√¢neas
- **Sess√£o Persistente**: Login √∫nico reutilizado
- Cache de consultas recentes
- Pool de conex√µes otimizado
- Monitoring de performance e carga
- Timeouts adequados para consultas longas
- Headers de status de pool (`X-Pool-Available`, `X-Pool-Active`)

### Confiabilidade
- Retry autom√°tico em falhas de rede
- Failover para m√∫ltiplas inst√¢ncias
- Backup autom√°tico da sess√£o
- Alertas para falhas consecutivas

## Configura√ß√µes Recomendadas para Produ√ß√£o

### Capacidade de Concorr√™ncia
- **Pool Size**: 3-5 p√°ginas simult√¢neas
- **Max Workers**: 1 (Gunicorn/Uvicorn)
- **Limit Concurrency**: 10 conex√µes
- **Timeout**: 30s para obter p√°gina do pool
- **Session Timeout**: 2 horas

### Headers de Monitoramento
- `X-Pool-Available`: P√°ginas dispon√≠veis no pool
- `X-Pool-Active`: P√°ginas atualmente em uso
- `X-Session-Status`: Status da sess√£o principal

### Exemplo de Uso
```bash
# Requisi√ß√£o √∫nica
curl -X POST "http://localhost:8000/cnpj" \
  -H "Content-Type: application/json" \
  -d '{"cnpj": "12.345.678/0001-90"}'

# M√∫ltiplas requisi√ß√µes paralelas (at√© 3 simult√¢neas)
curl -X POST "http://localhost:8000/cnpj" -d '{"cnpj": "11111111000111"}' &
curl -X POST "http://localhost:8000/cnpj" -d '{"cnpj": "22222222000122"}' &
curl -X POST "http://localhost:8000/cnpj" -d '{"cnpj": "33333333000133"}' &

# Status do pool
curl "http://localhost:8000/status"
```